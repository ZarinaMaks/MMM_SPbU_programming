{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# Part 1"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Loading the dataset"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import numpy as np\n",
        "from numpy.lib.recfunctions import structured_to_unstructured"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "data = np.genfromtxt('iris.data', delimiter=\",\", encoding=\"utf8\", dtype=None)\n",
        "features = structured_to_unstructured(data[[\"f0\", \"f1\", \"f2\", \"f3\"]])\n",
        "names = data[\"f4\"]\n",
        "f\"Memory size: {features.nbytes + names.nbytes} bytes\""
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "features"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Normalizing"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "norm_features = (features - features.min(axis=0)) \/ (features.max(axis=0) - features.min(axis=0))\n",
        "norm_features"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Defining fourth feature as a categorical variable"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "first_q = np.quantile(norm_features[3], 0.25)\n",
        "second_q = np.quantile(norm_features[3], 0.75)\n",
        "\n",
        "fc = norm_features[:,3]\n",
        "third_feature_column = np.where(fc < first_q, \"small\", np.where(fc > second_q, \"big\", \"medium\"))\n",
        "third_feature_column"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Splitting dataset into two"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def get_sets(f, n):\n",
        "    indices = np.random.permutation(f.shape[0])\n",
        "    train_percentage = int(f.shape[0] * 0.8)\n",
        "    training_idx, test_idx = indices[:train_percentage], indices[train_percentage:]\n",
        "\n",
        "    training_features, training_names = f[training_idx], n[training_idx]\n",
        "    test_features, test_names = f[test_idx], n[test_idx]\n",
        "    return training_features, training_names, test_features, test_names"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tr_f, tr_n, te_f, te_n = get_sets(features, names)\n",
        "f\"{tr_f.shape[0]} rows in training set, {te_f.shape[0]} rows in testing set\""
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Part 2"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Data classification (testing classifier SVC on various selections)"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import sklearn as sk\n",
        "from sklearn import svm"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def get_stats(expected, actual):\n",
        "    wrong_predictions = [f\"Expected: {w}, actual {c}\" for w,c in dict(zip(expected, actual)).items() if w != c]\n",
        "    accuracy = (len(expected) - len(wrong_predictions)) \/ len(expected)\n",
        "    return wrong_predictions, accuracy"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def test_classifier(clf, num_of_tests=20):\n",
        "    np.random.seed(42)\n",
        "    for i in range(num_of_tests):\n",
        "        train_f, train_n, test_f, test_n = get_sets(features, names)\n",
        "        clf = sk.base.clone(clf)\n",
        "        clf.fit(train_f, train_n)\n",
        "        wp, score = get_stats(test_n, clf.predict(test_f))\n",
        "        print(f\"Iteration: {i}\\n Wrong predictions: {wp}\\n Score: {score}\\n\")\n",
        "\n",
        "test_classifier(svm.SVC(), 100)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**The classifier was tested on several samples of the same dataset. Average accuracy: 0.9 - 1. Most often the classifier confuses \"Iris-virginica\" and \"Iris-versicolor\".**"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Experiments with hyperparameters\n",
        "  Testing different kernels with different parameters"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def get_average_score(clf, num_of_tests=1000, normalized=True):\n",
        "    np.random.seed(42)\n",
        "    clf = sk.base.clone(clf)\n",
        "    points = 0\n",
        "    f = norm_features if normalized else features\n",
        "    for i in range(num_of_tests):\n",
        "        train_f, train_n, test_f, test_n = get_sets(f, names)\n",
        "        clf.fit(train_f, train_n)\n",
        "        points += clf.score(test_f, test_n)\n",
        "    return points \/ num_of_tests"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 1. Testing rbf kernel"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=1, kernel='rbf'), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=1, kernel=\"rbf\"), normalized=False) "
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.7, kernel=\"rbf\"), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.7, kernel=\"rbf\"), normalized=False)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.5, kernel=\"rbf\"), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.5, kernel=\"rbf\"), normalized=False)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**Conclusion**: Best result without normalization with higher C"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 2. Testing linear kernel"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=1, kernel=\"linear\"), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=1, kernel=\"linear\"), normalized=False)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.5, kernel=\"linear\"), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.5, kernel=\"linear\"), normalized=False)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**Conclusion:** Best result without normalization with C near 0.5"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### 3. Testing poly kernel"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=1, kernel=\"poly\"), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=1, kernel=\"poly\"), normalized=False)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.5, kernel=\"poly\"), normalized=True)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "get_average_score(svm.SVC(C=0.5, kernel=\"poly\"), normalized=False)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**Conclusion**: Best results with normalization with higher C"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "- ## Vizualizing dataset"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn import decomposition\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "pca = decomposition.PCA(n_components=2)\n",
        "pca.fit(features)\n",
        "dec_features = pca.transform(features)\n",
        "dec_features"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "np.random.seed(42)\n",
        "train_f, train_n, test_f, test_n = get_sets(dec_features, names)\n",
        "\n",
        "clf = svm.SVC(C=0.5, kernel=\"linear\")\n",
        "clf.fit(train_f, train_n)\n",
        "clf.score(test_f, test_n)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "colours = np.unique(test_n, return_inverse=True)[1]\n",
        "labels = np.unique(test_n, return_inverse=True)[0].tolist()\n",
        "\n",
        "sc = plt.scatter(test_f[:,0], test_f[:,1], c=colours, edgecolors=\"k\")\n",
        "plt.title(\"Original dataset classification\")\n",
        "plt.legend(handles=sc.legend_elements()[0], labels=labels)\n",
        "\n",
        "plt.xlim([-3.5, 4])\n",
        "plt.ylim([-1.5, 1.5])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**Now it's clear why classifier confuses iris-versicolor and iris-virginica. Let's see how classifieir predicts labels for such data**"
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "predicted = np.unique(clf.predict(test_f), return_inverse=True)[1]\n",
        "\n",
        "pr_sc = plt.scatter(test_f[:,0], test_f[:,1], c=predicted, edgecolors=\"k\")\n",
        "plt.title(\"Predicted values classification\")\n",
        "plt.legend(handles=pr_sc.legend_elements()[0], labels=labels)\n",
        "\n",
        "plt.xlim([-3.5, 4])\n",
        "plt.ylim([-1.5, 1.5])\n",
        "plt.show()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}