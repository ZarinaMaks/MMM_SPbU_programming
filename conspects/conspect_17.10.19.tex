\documentclass[a4paper,12pt]{article}
\usepackage{cmap}
\usepackage {listings}
\usepackage{verbatim}
\usepackage {misccorr}
\usepackage{graphicx}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsfonts}
\author{Зарина}
\title{Master-theorem}
\date{6 ноября 2019}
\usepackage{indentfirst}
\begin{document}
\section{Master-theorem}
Пусть имеется задача  O(n), которая разбивается на несколько подзадач $O(\frac{n}{m})$
\begin{displaymath}
T(n) = \left\{ \begin{array}{ll}
 O(1), & \textrm{n=1}\\
 k*T(\frac{n}{m})+O(n^c) & \textrm{n>1}\\
  \end{array} \right.
\end{displaymath}\\
где $k\in\mathbb{N},m\in\mathbb{R}, m>1,c\in\mathbb{R}^+ $\\
1)$c>log_mk <=>T(n)=O(n^c)$\\
2)$c<log_mk <=>T(n) = O(n^{log_mk})$\\
3)$c=log_mk <=>T(n) = O(n^c*log_mk)$\\

\textbf{Доказательство:}\\Рассмотрим дерево рекурсии данного соотношения. Всего в нем будет $log_mk$ уровней. На каждом таком уровне, количество ветвлений в дереве будет умножаться на k, так на уровне i будет $a^i$ ветвлений. Также известно, что каждое ветвление на уровне i размера $\frac{n}{m^i}$.  Ветвление размера $\frac{n}{m^i}$ требует $O((\frac{n}{m^i})^c)$ дополнительных затрат, поэтому общее количество совершённых действий на уровне i:$O(k^i(\frac{n}{m^i}))=O(n^c(\frac{k}{m^c})^i)$. 
\\Заметим, что количество операций увеличивается/уменьшается/остаётся константой, если $(\frac{k}{m^c}^i)$ увеличивается/уменьшается/остаётся константой соответственно.\\
Поэтому решение разбивается на три случая, когда$(\frac{k}{m^c})^i$:\\
1) больше 1\\
2) равна 1\\
3) меньше 1\\
Рассмотрим $\frac{k}{m^c} = 1 <=> a = b^c <=> log_mk = clog_mm <=> log_ba = c$\\
Распишем всю работу в течение рекурсивного спуска:\\
$T(n) = \sum_{i=0}^{log_mN}O(n^c*(\frac{k}{m^c})^i)+O(1)=O(n^c*\sum_{i=0}^{log_mN}(\frac{k}{m^c})^i)$\\
Откуда получаем:\\

1) $c>log_mk => T(n) = O(n^c)$ (так как $(\frac{k}{m^c})^i$) убывающая геометрическая прогрессия)\\

2) $c=log_mk => T(n) = \sum_{i=0}^{log_mN}n^c*(\frac{k}{m^c})^i=n^c*\sum_{i=0}^{log_mN}(\frac{k}{m^c})^i = n^c*\sum_{i=0}^{log_mN}*1^i = n^c+n^clog_mN = O(n^clogn)$\\

3) $c<log_mk=>$\\
$T(n) = \sum_{i=0}^{log_mN}n^c*(\frac{k}{m^c})^i =n^c*\sum_{i=0}^{log_mN}(\frac{k}{m^c})^i = O(n^c*(\frac{k}{m^c})^{log_mk}) = O(n^c*\frac{k^{log_mN}}{(m^c)^{log_mN}}) = O(n^c*\frac{N^{log_mk}}{n^c}) = O(n^{log_mk})$\\


\section{Примеры}
\noindent\textbf{1) Бинарный поиск}\\
Для бинарного поиска имеем: m = 2, k = 1, c = 0, так как константное время\\
Тогда $log_mk = lig_21 = 0 = c; T(n) = O(logN)$\\
\textbf{2) Cортировка слиянием}\\
Для сортировки слиянием имеем:  m = 2, k = 2, c = 1,  так как линейное время\\
$log_mk = log_22 = 1 = c; T(n) = O(nlogn)$\\
\textbf{3) Рассмотрим: $f(n) = n\sqrt{n+1}$}\\
$f(n) = n\sqrt{n+1}\leq n\sqrt{2n} = O(n^{3/2})$\\
\begin{displaymath}
T(n) = \left\{ \begin{array}{ll}
 2*T(n/3)+O(f(n)), & \textrm{n>1}\\
 \alpha & \textrm{}\\
  \end{array} \right.
\end{displaymath}\\
Тогда вся оценка сложности $T(n) = O(f(n))$(т.к. $log_32<3/2$)\\
\section{Примеры недопустимых соотношений}
\noindent$\mathbf{1)T(n) = 2^nT(\frac{n}{2})+O(n^n)}$\\
\indent K не является константой; количество подзадач может меняться\\
$\mathbf{2)T(n) = 2T(\frac{n}{2})+O(\frac{n}{logn})}$\\
 \indentРассмотрим $f(n) = \frac{n}{logn}$, тогда не существует такого $O(n^c)$, что $f(n) \in O(n^c)$, так как при  n=1, f(n)$\rightarrow$ $\infty$, а $O(n^c)$ ограниченно\\
$\mathbf{3)T(n) = 0.5T(\frac{n}{2})+O(n)}$\\
\indent|a| < 1, однако пример можно решить следующим образом: заметим, что на i шаге, размер $T(i)\leq\frac{c*n}{4^i}$, тогда оценивая сумму, рполучаем, что T(n) = O(n)\\
$\mathbf{4)T(n) = -2T(\frac{n}{3}) + O(n^2)}$\\
\indent a < 0 , прои составлении асимптотического решения перед О каждый раз будет новый знак, что противоречит мастер-теореме
\section{Умножение Карацубы}

У умножения столбиком оценка сложности $O(n^2)$, поскольку если перемножаем два числа, в которых по n цифр, то суммарно делаем n*n - перемножаем каждую цифру первого числа на каждую цифру второго\\

Теперь представим, что есть два числа A и B длиной n:\\
$A = a_{n-1}a_{n-2}...a_0$\\
$B = b_{n-1}a_{n-2}...a_0$, где $a_i, b_i$ — значение в соотв. разряде числа.\\

Каждое из них можно представить в виде суммы их двух частей, половинок длиной m = n / 2 (если n нечетное, то одна часть короче другой на один разряд:\\
$A_0 = a_{m-1}a_{m-2}...a_0$;      $B_0 = b_{m-1}b_{m-2}...b_0$\\
$A_1 = a_{n-1}a_{n-2}...a_m$;      $B1 = b_{n-1}b_{n-2}...b_m$\\
$A = A_0 + A_1 * 10^m$;    $B = B_0 + B_1 * 10^m$\\

Тогда: $A * B = ( A_0 + A_1 * 10^m ) * ( B_0 + B_1 * 10^m ) = A_0 * B_0 + A_0 * B_1 * 10^m + A_1 * B_0 * 10^m + A_1 * B_1 * 10^{2m} = \underline{A_0 * B_0} + \mathbf{( A_0 * B_1 + A_1 * B_0 )} * 10^m + A_1 * B_1 * 10^{2m}$\\

Здесь нужно 4 операции умножения. Но с другой стороны:\\
$( A_0 + A_1 ) * ( B_0 + B_1 ) = \underline{A_0 * B_0} + \mathbf{A_0 * B_1 + A_1 * B_0} + \underline{A_1 * B_1}$\\

Посмотрим на выделенные части в обоих формулах: после несложных преобразований количество операций умножения свели к 3-м, заменив два умножения на одно и несколько операций сложения и вычитания, время выполнения которых на порядок меньше:\\
$\mathbf{A_0 * B_1 + A_1 * B_0} = ( A_0 + A_1 ) * ( B_0 + B_1 ) - \underline{A_0 * B_0} - \underline{A_1 * B_1}$\\

\noindenВ итоге получим:
$A * B = A_0 * B_0 + (( A_0 + A_1 ) * ( B_0 + B_1 ) - A_0 * B_0 - A_1 * B_1 ) *10^m + A_1 * B_1 * 10^{2m} $\\

\noindentБыло k = 4, m = 2, c = 1\\
Стало K = 3, m = 2, c = 1\\

\textbf{Асимптотическая сложность:} $O(n^{log_23})$\\

Замечание: В 1971 году был разработан более быстрый алгоритм: метод умножения Шёнхаге - Штрассена со сложностью $O(N*logN*loglogN)$
\end{document}